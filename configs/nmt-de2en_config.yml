data_process:
  path:
    raw:
      src_train: data/nmt-de2en/raw/train_example.de
      trg_train: data/nmt-de2en/raw/train_example.en
      src_val: data/nmt-de2en/raw/val_example.de
      trg_val: data/nmt-de2en/raw/val_example.en
      src_test: data/nmt-de2en/raw/test_example.de
      trg_test: data/nmt-de2en/raw/test_example.en
    processed:
      train: data/nmt-de2en/processed/train.npz
      val: data/nmt-de2en/processed/val.npz
      test: data/nmt-de2en/processed/test.npz
      src_word2index: data/nmt-de2en/processed/src_word2index.pickle
      src_index2word: data/nmt-de2en/processed/src_index2word.pickle
      trg_word2index: data/nmt-de2en/processed/trg_word2index.pickle
      trg_index2word: data/nmt-de2en/processed/trg_index2word.pickle
  tokenizer: fair
  vocab:
    src:
      max_size: 30000
      min_freq: 1
    trg:
      max_size: 30000
      min_freq: 1
model:
  type: cnn
  rnn:
    src_vocab_size: 18560
    trg_vocab_size: 10842
    embed_size: 512
    rnn_type: LSTM
    hidden_size: 512
    num_layers: 2
    bidirectional: True
    dropout: 0.1
    share_decoder_embedding: True
  cnn:
    src_vocab_size: 18560
    trg_vocab_size: 10842
    embed_size: 256
    num_positions: 500
    hidden_size: 512
    kernel_size: 3
    num_layers: 8
    activate: glu
    dropout: 0.1
  transformer:
    src_vocab_size: 18560
    trg_vocab_size: 10842
    num_positions: 500
    d_model: 512
    num_heads: 8
    num_layers: 6
    dropout: 0.1
train:
  gpu: 3
  batch_size: 64
  learning_rate: 0.001
  num_epoches: 300
  clip: 5.0
  max_len: 64
  label_smoothing: 0.1